{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PVICE & Relog - PCA baselines for Si & CdTe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReEDS installation projections from the Solar Futures Study, published by DOE on 2021.\n",
    "\n",
    "Scenario Interest: \n",
    "o\t95-by-35+Elec.Adv+DR ,  a.k.a. \"Solar Futures Decarbonization + Electrification scenario\"\n",
    "\n",
    "This code performs three Methods to output files for the Mass Flows:\n",
    "<ol>\n",
    "    <li> PCA original data by ReEDS </li>\n",
    "    <li> PCA data reordered based on ascending production up to 2035, and then descending, </li>\n",
    "    <li> PCA data calculated with an exponencial that mathces the cumulative 2035 and 2050 targets </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PV_ICE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = os.getcwd()\n",
    "testfolder = os.path.join(cwd, 'TEMP')\n",
    "\n",
    "if not os.path.exists(testfolder):\n",
    "    os.makedirs(testfolder)\n",
    "print (\"Your simulation will be stored in %s\" % testfolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PV_ICE.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Reading a standard ReEDS output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reedsFile = os.path.join(cwd, 'baselines','December Core Scenarios ReEDS Outputs Solar Futures v3a.xlsx')\n",
    "print (\"Input file is stored in %s\" % reedsFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REEDSInput = pd.read_excel(reedsFile,\n",
    "#                        sheet_name=\"new installs PV (2)\")\n",
    "                       sheet_name=\"new installs PV\")\n",
    "\n",
    "#index_col=[0,2,3]) #this casts scenario, PCA and State as levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Save Input Files by PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a copy of the REEDS Input and modify structure for PCA focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf = REEDSInput.copy()\n",
    "rawdf.drop(columns=['State'], inplace=True)\n",
    "rawdf.drop(columns=['Tech'], inplace=True) #tech=pvtotal from \"new installs PV sheet\", so can drop\n",
    "rawdf.set_index(['Scenario','Year','PCA'], inplace=True)\n",
    "rawdf.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Loading Module Baseline. Will be used later to populate all the columns other than 'new_Installed_Capacity_[MW]' which will be supplied by the REEDS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = PV_ICE.Simulation(name='Simulation1', path=testfolder)\n",
    "r1.createScenario(name='cSi', massmodulefile= os.path.join(cwd, 'baselines', 'baseline_modules_mass_US_cSi.csv'))\n",
    "# MAC: I think we probably want noCircularity so everything goes to landfill and\n",
    "# it's easy to calculate the 'BEST case for Recycling scenario'. Otherwise comment out...\n",
    "r1.scenMod_noCircularity() \n",
    "\n",
    "\n",
    "baseline = r1.scenario['cSi'].dataIn_m\n",
    "baseline = baseline.drop(columns=['new_Installed_Capacity_[MW]'])\n",
    "baseline.set_index('year', inplace=True)\n",
    "baseline.index = pd.PeriodIndex(baseline.index, freq='A')  # A -- Annual\n",
    "baseline.head()\n",
    "\n",
    "r1.createScenario(name='CdTe', massmodulefile=os.path.join(cwd, 'baselines','baseline_modules_mass_US_CdTe.csv'))\n",
    "# MAC: I think we probably want noCircularity so everything goes to landfill and\n",
    "# it's easy to calculate the 'BEST case for Recycling scenario'. Otherwise comment out...\n",
    "r1.scenMod_noCircularity() \n",
    "baselineCdTe = r1.scenario['CdTe'].dataIn_m\n",
    "baselineCdTe = baselineCdTe.drop(columns=['new_Installed_Capacity_[MW]'])\n",
    "baselineCdTe.set_index('year', inplace=True)\n",
    "baselineCdTe.index = pd.PeriodIndex(baselineCdTe.index, freq='A')  # A -- Annual\n",
    "baselineCdTe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each Scenario and for each PCA, combine with baseline and save as input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set header dynamically\n",
    "import csv\n",
    "\n",
    "massmodulefile = os.path.join(cwd, 'baselines', 'baseline_modules_mass_US_cSi.csv')\n",
    "\n",
    "with open(massmodulefile, newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    row1 = next(reader)  # gets the first line\n",
    "    row2 = next(reader)  # gets the first line\n",
    "\n",
    "row11 = 'year'\n",
    "for x in row1[1:]:\n",
    "    row11 = row11 + ',' + x \n",
    "\n",
    "row22 = 'year'\n",
    "for x in row2[1:]:\n",
    "    row22 = row22 + ',' + x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MarketShare File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketsharefile = os.path.join(cwd, 'baselines','output_RELOG_cSi_CdTe_capacity_reeds.csv')\n",
    "marketshare = pd.read_csv(marketsharefile)\n",
    "# Not elegant but I need to trim down to ReEds year start which is 2010\n",
    "marketshare = marketshare[marketshare['Year']>=2010].reset_index(drop=True)\n",
    "marketshare.set_index('Year', inplace=True)\n",
    "marketshare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack for plots.\n",
    "sparkplot = True\n",
    "xvals = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017',\n",
    "             '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025',\n",
    "             '2026', '2027', '2028', '2029', '2030', '2031', '2032', '2033',\n",
    "             '2034', '2035', '2036', '2037', '2038', '2039', '2040', '2041',\n",
    "             '2042', '2043', '2044', '2045', '2046', '2047', '2048', '2049',\n",
    "             '2050']\n",
    "plt.rcParams.update({'font.size': 8})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning:</b>The file in 'baselines/output_RELOG_cSi_CdTe_capacity_reeds' drives the capacity installed for cSi and CdTe. The curreht file as of 2/17 has a zero on 2021 installed capacity for cristalline Siliconwhich is getting propagated to all PCAs.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorganize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range (len(rawdf.unstack(level=1))):\n",
    "    PCA = rawdf.unstack(level=1).iloc[ii].name[1] #This one iterates over the pca names: p1 to p99\n",
    "    SCEN = rawdf.unstack(level=1).iloc[ii].name[0] #This one iterates over all scenario names: \n",
    "                                                   # 95-by-35+Elec.Adv, 95-by-35.Adv, Reference.Adv+DR, etc\n",
    "    SCEN=SCEN.replace('+', '_')\n",
    "    filetitle = SCEN+'_cSI_'+PCA +'.csv' #These lines, 2 to 5 will allow to make file names\n",
    "    subtestfolder = os.path.join(testfolder, 'PCAs_RELOG_Method1') # Create folder of the scenarios\n",
    "    if not os.path.exists(subtestfolder): # Create folder if it doen's exist\n",
    "        os.makedirs(subtestfolder)\n",
    "    filetitle = os.path.join(subtestfolder, filetitle)\n",
    "    A = rawdf.unstack(level=1).iloc[ii]\n",
    "    A = A.droplevel(level=0)\n",
    "    A.name = 'new_Installed_Capacity_[MW]'\n",
    "    A = pd.DataFrame(A)\n",
    "    A.index=pd.PeriodIndex(A.index, freq='A')\n",
    "    A = pd.DataFrame(A)\n",
    "    B = A.copy()\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * marketshare['cSi Market Share'].values\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * 1000   # ReEDS file is in GW.\n",
    "    # Sort Ascending 2022 to 2035 new_Installed_Capacity_[MW]\n",
    "    # Sort Descending 2035 to 2050 new_Installed_Capacity_[MW]\n",
    "    if reorganize:\n",
    "        sortedB = (list(B.iloc[0:12]['new_Installed_Capacity_[MW]'].values) + list(B.iloc[12:25]['new_Installed_Capacity_[MW]'].sort_values().values)\n",
    "        +list(B.iloc[25::]['new_Installed_Capacity_[MW]'].sort_values(ascending=False).values))\n",
    "        sortedBdf = pd.DataFrame(sortedB, index = A.index, columns =['new_Installed_Capacity_[MW]'])\n",
    "        B = sortedBdf.reindex(A.index)\n",
    "    # Add other columns\n",
    "    B = pd.concat([B, baseline.reindex(A.index)], axis=1)\n",
    "   \n",
    "    header = row11 + '\\n' + row22 + '\\n'\n",
    "    \n",
    "    # SPARK PLOT\n",
    "    if sparkplot:\n",
    "        sparkplotfolder = os.path.join(subtestfolder, 'SPARKPLOTS')\n",
    "        if not os.path.exists(sparkplotfolder):\n",
    "            os.makedirs(sparkplotfolder)\n",
    "\n",
    "        fig, axs = plt.subplots(figsize=(8, 5), facecolor='w', edgecolor='k')\n",
    "        plt.plot(xvals, B['new_Installed_Capacity_[MW]'].values)\n",
    "        plt.xticks(rotation=45)\n",
    "        figtitle = 'PV ICE ' + SCEN + ' Baseline_Csi_'+PCA+'.png'\n",
    "        fig.savefig(os.path.join(sparkplotfolder, figtitle), dpi=600)\n",
    "        plt.close(fig) # This avoids the figure from displayig and getting all the warnings\n",
    "    with open(filetitle, 'w', newline='') as ict:\n",
    "    # Write the header lines, including the index variable for\n",
    "    # the last one if you're letting Pandas produce that for you.\n",
    "    # (see above).\n",
    "        for line in header:\n",
    "            ict.write(line)\n",
    "\n",
    "        #    savedata.to_csv(ict, index=False)\n",
    "        B.to_csv(ict, header=False)\n",
    "    \n",
    "    filetitle = SCEN+'_CdTe_'+PCA +'.csv'\n",
    "    filetitle = os.path.join(subtestfolder, filetitle)\n",
    "\n",
    "    B = A.copy()\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * marketshare['CdTe Market Share'].values\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * 1000   # ReEDS file is in GW.\n",
    "    if reorganize:\n",
    "        sortedB = (list(B.iloc[0:12]['new_Installed_Capacity_[MW]'].values) + list(B.iloc[12:25]['new_Installed_Capacity_[MW]'].sort_values().values)\n",
    "        +list(B.iloc[25::]['new_Installed_Capacity_[MW]'].sort_values(ascending=False).values))\n",
    "        sortedBdf = pd.DataFrame(sortedB, index = A.index, columns =['new_Installed_Capacity_[MW]'])\n",
    "        B = sortedBdf.reindex(A.index)\n",
    "    # Add other columns\n",
    "    B = pd.concat([B, baseline.reindex(A.index)], axis=1)\n",
    "    \n",
    "    with open(filetitle, 'w', newline='') as ict:\n",
    "    # Write the header lines, including the index variable for\n",
    "    # the last one if you're letting Pandas produce that for you.\n",
    "    # (see above).\n",
    "        for line in header:\n",
    "            ict.write(line)\n",
    "\n",
    "        #    savedata.to_csv(ict, index=False)\n",
    "        B.to_csv(ict, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning:</b>The file in 'baselines/output_RELOG_cSi_CdTe_capacity_reeds' drives the capacity installed for cSi and CdTe. The curreht file as of 2/17 has a zero on 2021 installed capacity for cristalline Siliconwhich is getting propagated to all PCAs.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range (len(rawdf.unstack(level=1))):\n",
    "    PCA = rawdf.unstack(level=1).iloc[ii].name[1] #This one iterates over the pca names: p1 to p99\n",
    "    SCEN = rawdf.unstack(level=1).iloc[ii].name[0] #This one iterates over all scenario names: 95-by-35+Elec.Adv, 95-by-35.Adv, Reference.Adv+DR, etc\n",
    "    SCEN=SCEN.replace('+', '_')\n",
    "    filetitle = SCEN+'_cSI_'+PCA +'.csv' #These lines, 2 to 5 will allow to make file names\n",
    "    subtestfolder = os.path.join(testfolder, 'PCAs_RELOG_Method2') # Create folder of the scenarios\n",
    "    if not os.path.exists(subtestfolder): # Create folder if it doen's exist\n",
    "        os.makedirs(subtestfolder)\n",
    "    filetitle = os.path.join(subtestfolder, filetitle)\n",
    "    A = rawdf.unstack(level=1).iloc[ii]\n",
    "    A = A.droplevel(level=0)\n",
    "    A.name = 'new_Installed_Capacity_[MW]'\n",
    "    A = pd.DataFrame(A)\n",
    "    A.index=pd.PeriodIndex(A.index, freq='A')\n",
    "    A = pd.DataFrame(A)\n",
    "    B = A.copy()\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * marketshare['cSi Market Share'].values\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * 1000   # ReEDS file is in GW.\n",
    "    # Sort Ascending 2022 to 2035 new_Installed_Capacity_[MW]\n",
    "    # Sort Descending 2035 to 2050 new_Installed_Capacity_[MW]\n",
    "    if reorganize:\n",
    "        sortedB = (list(B.iloc[0:12]['new_Installed_Capacity_[MW]'].values) + list(B.iloc[12:25]['new_Installed_Capacity_[MW]'].sort_values().values)\n",
    "        +list(B.iloc[25::]['new_Installed_Capacity_[MW]'].sort_values(ascending=False).values))\n",
    "        sortedBdf = pd.DataFrame(sortedB, index = A.index, columns =['new_Installed_Capacity_[MW]'])\n",
    "        B = sortedBdf.reindex(A.index)\n",
    "    # Add other columns\n",
    "    B = pd.concat([B, baseline.reindex(A.index)], axis=1)\n",
    "   \n",
    "    header = row11 + '\\n' + row22 + '\\n'\n",
    "    \n",
    "    # SPARK PLOT\n",
    "    if sparkplot:\n",
    "        fig, axs = plt.subplots(figsize=(8, 5), facecolor='w', edgecolor='k')\n",
    "        plt.plot(xvals, B['new_Installed_Capacity_[MW]'].values)\n",
    "        plt.xticks(rotation=45)\n",
    "        figtitle = 'PV ICE ' + SCEN + ' Baseline_Csi_'+PCA+'.png'\n",
    "        fig.savefig(os.path.join(sparkplotfolder, figtitle), dpi=600)\n",
    "        plt.close(fig) # This avoids the figure from displayig and getting all the warnings\n",
    "    with open(filetitle, 'w', newline='') as ict:\n",
    "    # Write the header lines, including the index variable for\n",
    "    # the last one if you're letting Pandas produce that for you.\n",
    "    # (see above).\n",
    "        for line in header:\n",
    "            ict.write(line)\n",
    "\n",
    "        #    savedata.to_csv(ict, index=False)\n",
    "        B.to_csv(ict, header=False)\n",
    "    \n",
    "    filetitle = SCEN+'_CdTe_'+PCA +'.csv'\n",
    "    filetitle = os.path.join(subtestfolder, filetitle)\n",
    "\n",
    "    B = A.copy()\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * marketshare['CdTe Market Share'].values\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * 1000   # ReEDS file is in GW.\n",
    "    if reorganize:\n",
    "        sortedB = (list(B.iloc[0:12]['new_Installed_Capacity_[MW]'].values) + list(B.iloc[12:25]['new_Installed_Capacity_[MW]'].sort_values().values)\n",
    "        +list(B.iloc[25::]['new_Installed_Capacity_[MW]'].sort_values(ascending=False).values))\n",
    "        sortedBdf = pd.DataFrame(sortedB, index = A.index, columns =['new_Installed_Capacity_[MW]'])\n",
    "        B = sortedBdf.reindex(A.index)\n",
    "    # Add other columns\n",
    "    B = pd.concat([B, baseline.reindex(A.index)], axis=1)\n",
    "    \n",
    "    with open(filetitle, 'w', newline='') as ict:\n",
    "    # Write the header lines, including the index variable for\n",
    "    # the last one if you're letting Pandas produce that for you.\n",
    "    # (see above).\n",
    "        for line in header:\n",
    "            ict.write(line)\n",
    "\n",
    "        #    savedata.to_csv(ict, index=False)\n",
    "        B.to_csv(ict, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warning:</b>The file in 'baselines/output_RELOG_cSi_CdTe_capacity_reeds' drives the capacity installed for cSi and CdTe. The curreht file as of 2/17 has a zero on 2021 installed capacity for cristalline Siliconwhich is getting propagated to all PCAs.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate2035 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heathers suggestion\n",
    "# Which I didnt really follow but would be better than the linear\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "# Function to calculate the power-law with constants a and b\n",
    "def power_law(x, a, b):\n",
    "    return a*np.power(x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR\n",
    "# some sort of exponential growth that still sums up tthe correct capacity would be ideal.\n",
    "# Currently jsut doing a linear division per year per location\n",
    "# Based on cumulative sum from 2022 to 2035, and 2035 to 2050.\n",
    "# yearly2035 = B.iloc[12:26]['new_Installed_Capacity_[MW]'].sum()/len(B.iloc[12:26])\n",
    "# yearly2050 = B.iloc[26::]['new_Installed_Capacity_[MW]'].sum()/len(B.iloc[26::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range (len(rawdf.unstack(level=1))):\n",
    "    PCA = rawdf.unstack(level=1).iloc[ii].name[1] #This one iterates over the pca names: p1 to p99\n",
    "    SCEN = rawdf.unstack(level=1).iloc[ii].name[0] #This one iterates over all scenario names: 95-by-35+Elec.Adv, 95-by-35.Adv, Reference.Adv+DR, etc\n",
    "    SCEN=SCEN.replace('+', '_')\n",
    "    filetitle = SCEN+'_cSI_'+PCA +'.csv' #These lines, 2 to 5 will allow to make file names\n",
    "    subtestfolder = os.path.join(testfolder, 'PCAs_RELOG_Method3') # Create folder of the scenarios\n",
    "    if not os.path.exists(subtestfolder): # Create folder if it doen's exist\n",
    "        os.makedirs(subtestfolder)\n",
    "    filetitle = os.path.join(subtestfolder, filetitle)\n",
    "    A = rawdf.unstack(level=1).iloc[ii]\n",
    "    A = A.droplevel(level=0)\n",
    "    A.name = 'new_Installed_Capacity_[MW]'\n",
    "    A = pd.DataFrame(A)\n",
    "    A.index=pd.PeriodIndex(A.index, freq='A')\n",
    "    A = pd.DataFrame(A)\n",
    "    B = A.copy()\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * marketshare['cSi Market Share'].values\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * 1000   # ReEDS file is in GW.\n",
    "    # Sort Ascending 2022 to 2035 new_Installed_Capacity_[MW]\n",
    "    # Sort Descending 2035 to 2050 new_Installed_Capacity_[MW]\n",
    "    if interpolate2035:\n",
    "        # LINEAR\n",
    "        # some sort of exponential growth that still sums up tthe correct capacity would be ideal.\n",
    "        # Currently jsut doing a linear division per year per location\n",
    "        yearly2035 = B.iloc[12:26]['new_Installed_Capacity_[MW]'].sum()/len(B.iloc[12:26])\n",
    "        yearly2050 = B.iloc[26::]['new_Installed_Capacity_[MW]'].sum()/len(B.iloc[26::])\n",
    "        n2022= B.iloc[12].name\n",
    "        n2035= B.iloc[25].name\n",
    "        n2036= B.iloc[26].name\n",
    "        n2050= B.iloc[-1].name\n",
    "        B.loc[n2022:n2035, 'new_Installed_Capacity_[MW]' ] = yearly2035\n",
    "        B.loc[n2036:n2050, 'new_Installed_Capacity_[MW]' ] = yearly2050\n",
    "    # Add other columns\n",
    "    B = pd.concat([B, baseline.reindex(A.index)], axis=1)\n",
    "   \n",
    "    header = row11 + '\\n' + row22 + '\\n'\n",
    "    \n",
    "    # SPARK PLOT\n",
    "    if sparkplot:\n",
    "        fig, axs = plt.subplots(figsize=(8, 5), facecolor='w', edgecolor='k')\n",
    "        plt.plot(xvals, B['new_Installed_Capacity_[MW]'].values)\n",
    "        plt.xticks(rotation=45)\n",
    "        figtitle = 'PV ICE ' + SCEN + ' Baseline_Csi_'+PCA+'.png'\n",
    "        fig.savefig(os.path.join(sparkplotfolder, figtitle), dpi=600)\n",
    "        plt.close(fig) # This avoids the figure from displayig and getting all the warnings\n",
    "    with open(filetitle, 'w', newline='') as ict:\n",
    "    # Write the header lines, including the index variable for\n",
    "    # the last one if you're letting Pandas produce that for you.\n",
    "    # (see above).\n",
    "        for line in header:\n",
    "            ict.write(line)\n",
    "\n",
    "        #    savedata.to_csv(ict, index=False)\n",
    "        B.to_csv(ict, header=False)\n",
    "    \n",
    "    filetitle = SCEN+'_CdTe_'+PCA +'.csv'\n",
    "    filetitle = os.path.join(subtestfolder, filetitle)\n",
    "\n",
    "    B = A.copy()\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * marketshare['CdTe Market Share'].values\n",
    "    B['new_Installed_Capacity_[MW]'] = B['new_Installed_Capacity_[MW]'] * 1000   # ReEDS file is in GW.\n",
    "    if interpolate2035:\n",
    "        # LINEAR\n",
    "        # some sort of exponential growth that still sums up tthe correct capacity would be ideal.\n",
    "        # Currently jsut doing a linear division per year per location\n",
    "        yearly2035 = B.iloc[12:26]['new_Installed_Capacity_[MW]'].sum()/len(B.iloc[12:26])\n",
    "        yearly2050 = B.iloc[26::]['new_Installed_Capacity_[MW]'].sum()/len(B.iloc[26::])\n",
    "        n2022= B.iloc[12].name\n",
    "        n2035= B.iloc[25].name\n",
    "        n2036= B.iloc[26].name\n",
    "        n2050= B.iloc[-1].name\n",
    "        B.loc[n2022:n2035, 'new_Installed_Capacity_[MW]' ] = yearly2035\n",
    "        B.loc[n2036:n2050, 'new_Installed_Capacity_[MW]' ] = yearly2050    # Add other columns\n",
    "    B = pd.concat([B, baseline.reindex(A.index)], axis=1)\n",
    "    \n",
    "    with open(filetitle, 'w', newline='') as ict:\n",
    "    # Write the header lines, including the index variable for\n",
    "    # the last one if you're letting Pandas produce that for you.\n",
    "    # (see above).\n",
    "        for line in header:\n",
    "            ict.write(line)\n",
    "\n",
    "        #    savedata.to_csv(ict, index=False)\n",
    "        B.to_csv(ict, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
